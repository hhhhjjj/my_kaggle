{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_round_testin  first_round_traini\tsubmit_example.csv\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data/data12632/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result.csv\r\n"
     ]
    }
   ],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. All changes under this directory will be kept even after reset. Please clean unnecessary files in time to speed up environment loading.\n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\n",
      "Requirement already satisfied: catboost in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (0.17.2)\n",
      "Requirement already satisfied: plotly in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from catboost) (4.1.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from catboost) (3.0.3)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from catboost) (0.24.2)\n",
      "Requirement already satisfied: graphviz in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from catboost) (0.11)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from catboost) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from catboost) (1.16.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from catboost) (1.3.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from plotly->catboost) (1.3.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from matplotlib->catboost) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from matplotlib->catboost) (2.8.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from matplotlib->catboost) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from pandas>=0.24.0->catboost) (2019.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (41.2.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\n",
      "Requirement already satisfied: mlxtend in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (0.17.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from mlxtend) (3.0.3)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from mlxtend) (0.24.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from mlxtend) (41.2.0)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from mlxtend) (0.13.2)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from mlxtend) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from mlxtend) (1.16.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from mlxtend) (0.21.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from matplotlib>=3.0.0->mlxtend) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from matplotlib>=3.0.0->mlxtend) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from pandas>=0.24.2->mlxtend) (2019.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from python-dateutil>=2.1->matplotlib>=3.0.0->mlxtend) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\r\n",
      "Requirement already satisfied: xgboost in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (0.90)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from xgboost) (1.16.4)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from xgboost) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\r\n",
      "Requirement already satisfied: lightgbm in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (2.2.3)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from lightgbm) (0.21.2)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from lightgbm) (1.3.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from lightgbm) (1.16.4)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from scikit-learn->lightgbm) (0.13.2)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ! pip install auto-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import catboost as cbt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from mlxtend.classifier import StackingClassifier\r\n",
    "from xgboost import XGBClassifier\r\n",
    "import lightgbm as lgb\r\n",
    "from lightgbm import LGBMClassifier\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\r\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score,log_loss\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn.metrics import fbeta_score, make_scorer\r\n",
    "# from tqdm import tqdm\r\n",
    "import matplotlib as mpl\r\n",
    "mpl.use('Agg')\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import time\r\n",
    "import copy\r\n",
    "import gc\r\n",
    "import os\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/home/aistudio/data/data12632/first_round_traini')\r\n",
    "test_data = pd.read_csv('/home/aistudio/data/data12632/first_round_testin', encoding='utf-8')\r\n",
    "dit = {'Excellent':0,'Good':1,'Pass':2,'Fail':3}\r\n",
    "train_data['Quality_label'] = train_data['Quality_label'].map(dit)\r\n",
    "labels = pd.get_dummies(train_data['Quality_label']).values\r\n",
    "submit = pd.read_csv('/home/aistudio/data/data12632/submit_example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# features = ['Parameter5', 'Parameter7', 'Parameter8', 'Parameter9', 'Parameter10']\r\n",
    "# train_data[features] = np.log(train_data[features] + 1e-5)\r\n",
    "# test_data[features] = np.log(test_data[features] + 1e-5)\r\n",
    "# scale_features = []\r\n",
    "# for feature in features:\r\n",
    "#     for feature1 in features:\r\n",
    "#         train_data[str(feature)+\"_\"+str(feature1)] = train_data[feature]+train_data[feature1]\r\n",
    "#         train_data[str(feature)+\"mul\"+str(feature1)] = train_data[feature].mul(train_data[feature1])\r\n",
    "#         train_data[str(feature)+\"%\"+str(feature1)] = train_data[feature]%train_data[feature1]\r\n",
    "#         train_data[str(feature)+\"/\"+str(feature1)] = train_data[feature]/train_data[feature1]\r\n",
    "        \r\n",
    "#         scale_features.append(str(feature)+\"_\"+str(feature1))\r\n",
    "#         scale_features.append(str(feature)+\"mul\"+str(feature1))\r\n",
    "#         scale_features.append(str(feature)+\"%\"+str(feature1))\r\n",
    "#         scale_features.append(str(feature)+\"/\"+str(feature1))\r\n",
    "\r\n",
    "# # 组合所有特征\r\n",
    "# features = features + scale_features\r\n",
    "# print(features)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all train features: ['Parameter5', 'Parameter7', 'Parameter8', 'Parameter9', 'Parameter10', '7_9', '8_9', '7_8', '9_10', '7_10', '9%8', '7/8', '7%8', '8/9']\n",
      "Parameter5: 132\n",
      "Parameter7: 14\n",
      "Parameter8: 23\n",
      "Parameter9: 16\n",
      "Parameter10: 41\n",
      "7_9: 49\n",
      "8_9: 52\n",
      "7_8: 43\n",
      "9_10: 260\n",
      "7_10: 291\n",
      "9%8: 49\n",
      "7/8: 43\n",
      "7%8: 41\n",
      "8/9: 52\n"
     ]
    }
   ],
   "source": [
    "# 取parameter5-10，取log\r\n",
    "features = ['Parameter5', 'Parameter7', 'Parameter8', 'Parameter9', 'Parameter10']\r\n",
    "train_data[features] = np.log(train_data[features] + 1e-5)\r\n",
    "test_data[features] = np.log(test_data[features] + 1e-5)\r\n",
    "# 特征融合\r\n",
    "# train_data['5_6'] = train_data['Parameter5'] + train_data['Parameter6']\r\n",
    "# test_data['5_6'] = test_data['Parameter5'] + test_data['Parameter6']\r\n",
    "train_data['5_7'] = train_data['Parameter5'] + train_data['Parameter7']\r\n",
    "test_data['5_7'] = test_data['Parameter5'] + test_data['Parameter7']\r\n",
    "train_data['7_8'] = train_data['Parameter7'] + train_data['Parameter8']\r\n",
    "test_data['7_8'] = test_data['Parameter7'] + test_data['Parameter8']\r\n",
    "train_data['7_9'] = train_data['Parameter7'] + train_data['Parameter9']\r\n",
    "test_data['7_9'] = test_data['Parameter7'] + test_data['Parameter9']\r\n",
    "train_data['7_10'] = train_data['Parameter7'] + train_data['Parameter10']\r\n",
    "test_data['7_10'] = test_data['Parameter7'] + test_data['Parameter10']\r\n",
    "train_data['8_9'] = train_data['Parameter8'] + train_data['Parameter9']\r\n",
    "test_data['8_9'] = test_data['Parameter8'] + test_data['Parameter9']\r\n",
    "train_data['8_10'] = train_data['Parameter8'] + train_data['Parameter10']\r\n",
    "test_data['8_10'] = test_data['Parameter8'] + test_data['Parameter10']\r\n",
    "train_data['9_10'] = train_data['Parameter9'] + train_data['Parameter10']\r\n",
    "test_data['9_10'] = test_data['Parameter9'] + test_data['Parameter10']\r\n",
    "\r\n",
    "train_data['5_10'] = train_data['Parameter5'] + train_data['Parameter10']\r\n",
    "test_data['5_10'] = test_data['Parameter5'] + test_data['Parameter10']\r\n",
    "# train_data['6_10'] = train_data['Parameter6'] + train_data['Parameter10']\r\n",
    "# test_data['6_10'] = test_data['Parameter6'] + test_data['Parameter10']\r\n",
    "train_data['7_8_9'] = train_data['Parameter7'] + train_data['Parameter8'] + train_data['Parameter9']\r\n",
    "test_data['7_8_9'] = test_data['Parameter7'] + test_data['Parameter8'] + test_data['Parameter9']\r\n",
    "train_data['7_9_10'] = train_data['Parameter7'] + train_data['Parameter9'] + train_data['Parameter10']\r\n",
    "test_data['7_9_10'] = test_data['Parameter7'] + test_data['Parameter9'] + test_data['Parameter10']\r\n",
    "train_data['7_8_10'] = train_data['Parameter7'] + train_data['Parameter8'] + train_data['Parameter10']\r\n",
    "test_data['7_8_10'] = test_data['Parameter7'] + test_data['Parameter8'] + test_data['Parameter10']\r\n",
    "train_data['8_9_10'] = train_data['Parameter8'] + train_data['Parameter9'] + train_data['Parameter10']\r\n",
    "test_data['8_9_10'] = test_data['Parameter8'] + test_data['Parameter9'] + test_data['Parameter10']\r\n",
    "train_data['7_8_9_10'] = train_data['Parameter7'] + train_data['Parameter8'] + train_data['Parameter9'] + train_data['Parameter10']\r\n",
    "test_data['7_8_9_10'] = test_data['Parameter7'] + test_data['Parameter8'] + test_data['Parameter9'] + test_data['Parameter10']\r\n",
    "\r\n",
    "# train_data['5-6'] = (train_data['Parameter5'] - train_data['Parameter6'])\r\n",
    "# test_data['5-6'] = (test_data['Parameter5'] - test_data['Parameter6'])\r\n",
    "train_data['7-8'] = (train_data['Parameter7'] - train_data['Parameter8'])\r\n",
    "test_data['7-8'] = (test_data['Parameter7'] - test_data['Parameter8'])\r\n",
    "train_data['7-9'] = (train_data['Parameter7'] - train_data['Parameter9'])\r\n",
    "test_data['7-9'] = (test_data['Parameter7'] - test_data['Parameter9'])\r\n",
    "train_data['7-10'] = (train_data['Parameter7'] - train_data['Parameter10'])\r\n",
    "test_data['7-10'] = (test_data['Parameter7'] - test_data['Parameter10'])\r\n",
    "train_data['8-9'] = (train_data['Parameter8'] - train_data['Parameter9'])\r\n",
    "test_data['8-9'] = (test_data['Parameter8'] - test_data['Parameter9'])\r\n",
    "train_data['8-10'] = (train_data['Parameter8'] - train_data['Parameter10'])\r\n",
    "test_data['8-10'] = (test_data['Parameter8'] - test_data['Parameter10'])\r\n",
    "train_data['9-10'] = (train_data['Parameter9'] - train_data['Parameter10'])\r\n",
    "test_data['9-10'] = (test_data['Parameter9'] - test_data['Parameter10'])\r\n",
    "\r\n",
    "# train_data['5_6_mul'] = train_data['Parameter5'].mul(train_data['Parameter6'])\r\n",
    "# test_data['5_6_mul'] = test_data['Parameter5'].mul(test_data['Parameter6'])\r\n",
    "train_data['7_8_mul'] = train_data['Parameter7'].mul(train_data['Parameter8'])\r\n",
    "test_data['7_8_mul'] = test_data['Parameter7'].mul(test_data['Parameter8'])\r\n",
    "train_data['7_9_mul'] = train_data['Parameter7'].mul(train_data['Parameter9'])\r\n",
    "test_data['7_9_mul'] = test_data['Parameter7'].mul(test_data['Parameter9'])\r\n",
    "train_data['7_10_mul'] = train_data['Parameter7'].mul(train_data['Parameter10'])\r\n",
    "test_data['7_10_mul'] = test_data['Parameter7'].mul(test_data['Parameter10'])\r\n",
    "train_data['8_9_mul'] = train_data['Parameter8'].mul(train_data['Parameter9'])\r\n",
    "test_data['8_9_mul'] = test_data['Parameter8'].mul(test_data['Parameter9'])\r\n",
    "train_data['8_10_mul'] = train_data['Parameter8'].mul(train_data['Parameter10'])\r\n",
    "test_data['8_10_mul'] = test_data['Parameter8'].mul(test_data['Parameter10'])\r\n",
    "train_data['9_10_mul'] = train_data['Parameter9'].mul(train_data['Parameter10'])\r\n",
    "test_data['9_10_mul'] = test_data['Parameter9'].mul(test_data['Parameter10'])\r\n",
    "\r\n",
    "train_data['78_mul_79'] = (train_data['7_8'].mul(train_data['7_9']))\r\n",
    "test_data['78_mul_79'] = (test_data['7_8'].mul(test_data['7_9']))\r\n",
    "train_data['78_mul_710'] = (train_data['7_8'].mul(train_data['7_10']))\r\n",
    "test_data['78_mul_710'] = (test_data['7_8'].mul(test_data['7_10']))\r\n",
    "train_data['78_mul_89'] = (train_data['7_8'].mul(train_data['8_9']))\r\n",
    "test_data['78_mul_89'] = (test_data['7_8'].mul(test_data['8_9']))\r\n",
    "train_data['78_mul_810'] = (train_data['7_8'].mul(train_data['8_10']))\r\n",
    "test_data['78_mul_810'] = (test_data['7_8'].mul(test_data['8_10']))\r\n",
    "train_data['78_mul_910'] = (train_data['7_8'].mul(train_data['9_10']))\r\n",
    "test_data['78_mul_910'] = (test_data['7_8'].mul(test_data['9_10']))\r\n",
    "train_data['79_mul_710'] = (train_data['7_9'].mul(train_data['7_10']))\r\n",
    "test_data['79_mul_710'] = (test_data['7_9'].mul(test_data['7_10']))\r\n",
    "train_data['79_mul_89'] = (train_data['7_9'].mul(train_data['8_9']))\r\n",
    "test_data['79_mul_89'] = (test_data['7_9'].mul(test_data['8_9']))\r\n",
    "train_data['79_mul_810'] = (train_data['7_9'].mul(train_data['8_10']))\r\n",
    "test_data['79_mul_810'] = (test_data['7_9'].mul(test_data['8_10']))\r\n",
    "train_data['79_mul_910'] = (train_data['7_9'].mul(train_data['9_10']))\r\n",
    "test_data['79_mul_910'] = (test_data['7_9'].mul(test_data['9_10']))\r\n",
    "train_data['710_mul_89'] = (train_data['7_10'].mul(train_data['8_9']))\r\n",
    "test_data['710_mul_89'] = (test_data['7_10'].mul(test_data['8_9']))\r\n",
    "train_data['710_mul_810'] = (train_data['7_10'].mul(train_data['8_10']))\r\n",
    "test_data['710_mul_810'] = (test_data['7_10'].mul(test_data['8_10']))\r\n",
    "train_data['710_mul_910'] = (train_data['7_10'].mul(train_data['9_10']))\r\n",
    "test_data['710_mul_910'] = (test_data['7_10'].mul(test_data['9_10']))\r\n",
    "train_data['89_mul_810'] = (train_data['8_9'].mul(train_data['8_10']))\r\n",
    "test_data['89_mul_810'] = (test_data['8_9'].mul(test_data['8_10']))\r\n",
    "train_data['89_mul_910'] = (train_data['8_9'].mul(train_data['9_10']))\r\n",
    "test_data['89_mul_910'] = (test_data['8_9'].mul(test_data['9_10']))\r\n",
    "train_data['810_mul_910'] = (train_data['8_10'].mul(train_data['9_10']))\r\n",
    "test_data['810_mul_910'] = (test_data['8_10'].mul(test_data['9_10']))\r\n",
    "\r\n",
    "train_data['5_8'] = train_data['Parameter5'] + train_data['Parameter8']\r\n",
    "test_data['5_8'] = test_data['Parameter5'] + test_data['Parameter8']\r\n",
    "train_data['7+8*8'] = train_data['Parameter7'] + train_data['Parameter8'] * train_data['Parameter8']\r\n",
    "test_data['7+8*8'] = test_data['Parameter7'] + test_data['Parameter8'] * test_data['Parameter8']\r\n",
    "train_data['7*7+8'] = train_data['Parameter7'] * train_data['Parameter7'] + train_data['Parameter8']\r\n",
    "test_data['7*7+8'] = test_data['Parameter7'] * test_data['Parameter7'] + test_data['Parameter8']\r\n",
    "\r\n",
    "train_data['9/7'] = train_data['Parameter9'] / train_data['Parameter7']\r\n",
    "test_data['9/7'] = test_data['Parameter9'] / test_data['Parameter7']\r\n",
    "train_data['9/8'] = train_data['Parameter9'] / train_data['Parameter8']\r\n",
    "test_data['9/8'] = test_data['Parameter9'] / test_data['Parameter8']\r\n",
    "train_data['1/7'] = 1. / train_data['Parameter7']\r\n",
    "test_data['1/7'] = 1. / test_data['Parameter7']\r\n",
    "train_data['9%8'] = train_data['Parameter9'] % train_data['Parameter8']\r\n",
    "test_data['9%8'] = test_data['Parameter9'] % test_data['Parameter8']\r\n",
    "train_data['7%9'] = train_data['Parameter7'] % train_data['Parameter9']\r\n",
    "test_data['7%9'] = test_data['Parameter7'] % test_data['Parameter9']\r\n",
    "train_data['1/9'] = 1. / train_data['Parameter9']\r\n",
    "test_data['1/9'] = 1. / test_data['Parameter9']\r\n",
    "train_data['7/8'] = train_data['Parameter7'] / train_data['Parameter8']\r\n",
    "test_data['7/8'] = test_data['Parameter7'] / test_data['Parameter8']\r\n",
    "train_data['5%7'] = train_data['Parameter5'] % train_data['Parameter7']\r\n",
    "test_data['5%7'] = test_data['Parameter5'] % test_data['Parameter7']\r\n",
    "train_data['8%9'] = train_data['Parameter8'] % train_data['Parameter9']\r\n",
    "test_data['8%9'] = test_data['Parameter8'] % test_data['Parameter9']\r\n",
    "train_data['7/9'] = train_data['Parameter7'] / train_data['Parameter9']\r\n",
    "test_data['7/9'] = test_data['Parameter7'] / test_data['Parameter9']\r\n",
    "train_data['8/7'] = train_data['Parameter8'] / train_data['Parameter7']\r\n",
    "test_data['8/7'] = test_data['Parameter8'] / test_data['Parameter7']\r\n",
    "train_data['1/8'] = 1. / train_data['Parameter8']\r\n",
    "test_data['1/8'] = 1. / test_data['Parameter8']\r\n",
    "train_data['8%7'] = train_data['Parameter8'] % train_data['Parameter7']\r\n",
    "test_data['8%7'] = test_data['Parameter8'] % test_data['Parameter7']\r\n",
    "train_data['8+9/8%9'] = (train_data['Parameter8'] + train_data['Parameter9']) / train_data['Parameter8'] % train_data['Parameter9']\r\n",
    "test_data['8+9/8%9'] = (test_data['Parameter8'] + test_data['Parameter9']) / test_data['Parameter8'] % test_data['Parameter9']\r\n",
    "train_data['7%8'] = train_data['Parameter7'] % train_data['Parameter8']\r\n",
    "test_data['7%8'] = test_data['Parameter7'] % test_data['Parameter8']\r\n",
    "train_data['8/9'] = train_data['Parameter8'] / train_data['Parameter9']\r\n",
    "test_data['8/9'] = test_data['Parameter8'] / test_data['Parameter9']\r\n",
    "\r\n",
    "train_data['7+8%7+9'] = train_data['Parameter7'] + train_data['Parameter8'] % train_data['Parameter7'] + train_data['Parameter9']\r\n",
    "test_data['7+8%7+9'] = test_data['Parameter7'] + test_data['Parameter8'] % test_data['Parameter7'] + test_data['Parameter9']\r\n",
    "train_data['1/8/9'] = 1./train_data['Parameter8']/train_data['Parameter9']\r\n",
    "test_data['1/8/9'] = 1./test_data['Parameter8']/test_data['Parameter9']\r\n",
    "train_data['9%7/9'] = train_data['Parameter9']%train_data['Parameter7']/train_data['Parameter9']\r\n",
    "test_data['9%7/9'] = test_data['Parameter9']%test_data['Parameter7']/test_data['Parameter9']\r\n",
    "train_data['8+9/8*9'] = train_data['Parameter8']+train_data['Parameter9']/train_data['Parameter8']*train_data['Parameter9']\r\n",
    "test_data['8+9/8*9'] = test_data['Parameter8']+test_data['Parameter9']/test_data['Parameter8']*test_data['Parameter9']\r\n",
    "train_data['9%7/7*8'] = train_data['Parameter9']%train_data['Parameter7']/train_data['Parameter7']*train_data['Parameter8']\r\n",
    "test_data['9%7/7*8'] = test_data['Parameter9']%test_data['Parameter7']/test_data['Parameter7']*test_data['Parameter8']\r\n",
    "train_data['7%8/7'] = train_data['Parameter7']%train_data['Parameter8']/train_data['Parameter7']\r\n",
    "test_data['7%8/7'] = test_data['Parameter7']%test_data['Parameter8']/test_data['Parameter7']\r\n",
    "train_data['9%8*9'] = train_data['Parameter9']%train_data['Parameter8']*train_data['Parameter9']\r\n",
    "test_data['9%8*9'] = test_data['Parameter9']%test_data['Parameter8']*test_data['Parameter9']\r\n",
    "train_data['8*9%7'] = train_data['Parameter8']*train_data['Parameter9']%train_data['Parameter7']\r\n",
    "test_data['8*9%7'] = test_data['Parameter8']*test_data['Parameter9']%test_data['Parameter7']\r\n",
    "\r\n",
    "train_data['8%9*8'] = train_data['Parameter8']%train_data['Parameter9']*train_data['Parameter8']\r\n",
    "test_data['8%9*8'] = test_data['Parameter8']%test_data['Parameter9']*test_data['Parameter8']\r\n",
    "train_data['7*8*9'] = train_data['Parameter8']*train_data['Parameter7']*train_data['Parameter9']\r\n",
    "test_data['7*8*9'] = test_data['Parameter8']*test_data['Parameter7']*test_data['Parameter9']\r\n",
    "train_data['8+9/7*8']=train_data['Parameter8']+train_data['Parameter9']/train_data['Parameter7']*train_data['Parameter9']\r\n",
    "test_data['8+9/7*8']=test_data['Parameter8']+test_data['Parameter9']/test_data['Parameter7']*test_data['Parameter9']\r\n",
    "train_data['8%7/(9%8)'] = train_data['Parameter8']%train_data['Parameter7']/(train_data['Parameter9']%train_data['Parameter8'])\r\n",
    "test_data['8%7/(9%8)'] = test_data['Parameter8']%test_data['Parameter7']/(test_data['Parameter9']%test_data['Parameter8'])\r\n",
    "train_data['7%8/(8%9)'] = train_data['Parameter7']%train_data['Parameter8']/(train_data['Parameter8']%train_data['Parameter9'])\r\n",
    "test_data['7%8/(8%9)'] = test_data['Parameter7']%test_data['Parameter8']/(test_data['Parameter8']%test_data['Parameter9'])\r\n",
    "train_data['8+9/(9%8)']=train_data['Parameter8']+train_data['Parameter9']/(train_data['Parameter9']%train_data['Parameter8'])\r\n",
    "test_data['8+9/(9%8)']=test_data['Parameter8']+test_data['Parameter9']/(test_data['Parameter9']%test_data['Parameter8'])\r\n",
    "train_data['8*(9%7)+8'] = train_data['Parameter8']*(train_data['Parameter9']%train_data['Parameter7']+train_data['Parameter8'])\r\n",
    "test_data['8*(9%7)+8'] = test_data['Parameter8']*(test_data['Parameter9']%test_data['Parameter7']+test_data['Parameter8'])\r\n",
    "train_data['7+8*9'] = train_data['Parameter7']+train_data['Parameter8']*train_data['Parameter9']\r\n",
    "test_data['7+8*9'] = test_data['Parameter7']+test_data['Parameter8']*test_data['Parameter9']\r\n",
    "train_data['7%8/(9%8)'] = train_data['Parameter7']%train_data['Parameter8']/(train_data['Parameter9']%train_data['Parameter8'])\r\n",
    "test_data['7%8/(9%8)'] = test_data['Parameter7']%test_data['Parameter8']/(test_data['Parameter9']%test_data['Parameter8'])\r\n",
    "train_data['9%8/(7%8)'] = train_data['Parameter9']%train_data['Parameter8']/(train_data['Parameter7']%train_data['Parameter8'])\r\n",
    "test_data['9%8/(7%8)'] = test_data['Parameter9']%test_data['Parameter8']/(test_data['Parameter7']%test_data['Parameter8'])\r\n",
    "train_data['5%8'] = train_data['Parameter5']%train_data['Parameter8']\r\n",
    "test_data['5%8'] = test_data['Parameter5']%test_data['Parameter8']\r\n",
    "# train_data['6%8'] = train_data['Parameter6']%train_data['Parameter8']\r\n",
    "# test_data['6%8'] = test_data['Parameter6']%test_data['Parameter8']\r\n",
    "train_data['10%8'] = train_data['Parameter10']%train_data['Parameter8']\r\n",
    "test_data['10%8'] = test_data['Parameter10']%test_data['Parameter8']\r\n",
    "\r\n",
    "train_data['7*8'] = train_data['Parameter7'] * train_data['Parameter8']\r\n",
    "test_data['7*8'] = test_data['Parameter7'] * test_data['Parameter8']\r\n",
    "train_data['5*5'] = train_data['Parameter5'] * train_data['Parameter5']\r\n",
    "test_data['5*5'] = test_data['Parameter5'] * test_data['Parameter5']\r\n",
    "# train_data['6*6'] = train_data['Parameter6'] * train_data['Parameter6']\r\n",
    "# test_data['6*6'] = test_data['Parameter6'] * test_data['Parameter6']\r\n",
    "train_data['7*7'] = train_data['Parameter7'] * train_data['Parameter7']\r\n",
    "test_data['7*7'] = test_data['Parameter7'] * test_data['Parameter7']\r\n",
    "train_data['8*8'] = train_data['Parameter8'] * train_data['Parameter8']\r\n",
    "test_data['8*8'] = test_data['Parameter8'] * test_data['Parameter8']\r\n",
    "train_data['9*9'] = train_data['Parameter9'] * train_data['Parameter9']\r\n",
    "test_data['9*9'] = test_data['Parameter9'] * test_data['Parameter9']\r\n",
    "train_data['10*10'] = train_data['Parameter10'] * train_data['Parameter10']\r\n",
    "test_data['10*10'] = test_data['Parameter10'] * test_data['Parameter10']\r\n",
    "\r\n",
    "scale_features = ['7_9','8_9', '7_8', '9_10', '7_10', '9%8','7/8','7%8','8/9'\r\n",
    "\t\t\t\t  ]\r\n",
    "\r\n",
    "\r\n",
    "# 组合所有特征\r\n",
    "features = features + scale_features\r\n",
    "\r\n",
    "print('all train features:', features)\r\n",
    "\r\n",
    "for fc in features:\r\n",
    "\tn = train_data['{}'.format(fc)].nunique()\r\n",
    "# \t这个的作用就是显示特征中的唯一值\r\n",
    "\tprint(fc + ':', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_data.sort_values('Parameter2', ascending=False)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\r\n",
    "# train\r\n",
    "# --------------------------------------------------------\r\n",
    "x_train = train_data[features].values\r\n",
    "x_test = test_data[features].values\r\n",
    "\r\n",
    "def lightgbm_model():\r\n",
    "\tmodel = LGBMClassifier(max_depth=5, learning_rate=0.01, n_estimators=1000, num_leaves=16,\r\n",
    "\t\t\t\t\t\t   objective='multiclass', silent=True,\r\n",
    "\t\t\t\t\t\t   reg_lambda=0.0001, #reg_alpha=1.,\r\n",
    "\t\t\t\t\t\t   #bagging_fraction=0.9, feature_fraction=0.9,\r\n",
    "\t\t\t\t\t\t   )\r\n",
    "\treturn model\r\n",
    "\r\n",
    "def xgboost_model():\r\n",
    "\tmodel = XGBClassifier(max_depth=5, n_estimators=1000, learning_rate=0.01, silent=True,min_child_weight=4,colsample_bytree=0.5,\r\n",
    "\t\t\t\t\t\t  #objective='multi:softmax'\r\n",
    "\t\t\t\t\t\t  )\r\n",
    "\treturn model\r\n",
    "\r\n",
    "def catboost_model():\r\n",
    "\tcbt_model = cbt.CatBoostClassifier(#iterations=100000, learning_rate=0.01, verbose=0,\r\n",
    "\t\titerations=3000, learning_rate=0.01, verbose=0,\r\n",
    "\t\tmax_depth=7, #reg_lambda=5.,\r\n",
    "\t\ttask_type='GPU',   # cat_features=cat_list,\r\n",
    "\t\tloss_function='MultiClass',\r\n",
    "# \t\tl2_leaf_reg = 7\r\n",
    "\t\t)\r\n",
    "\treturn cbt_model\r\n",
    "\r\n",
    "def rf_model():\r\n",
    "\tmodel = RandomForestClassifier(n_estimators=2000,max_depth=5,random_state=829,oob_score=True,min_samples_leaf=6,min_samples_split=3\r\n",
    "\t\t\t\t\t\t  )\r\n",
    "\treturn model\r\n",
    "\r\n",
    "def catboost_importance():\r\n",
    "\tmodel = catboost_model()\r\n",
    "\tmodel.fit(x_train, np.argmax(labels, 1))\r\n",
    "\timportance = model.get_feature_importance(prettified=True)\r\n",
    "# \t这个其实就是类似PCA一样，找到特征的贡献\r\n",
    "\tprint(importance.columns)\r\n",
    "\tfor i in range(len(features)):\r\n",
    "\t\tprint(features[int(importance['Feature Id'][i])] + ' :', importance['Importances'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sclf = StackingClassifier(classifiers=[lightgbm_model(),xgboost_model(),catboost_model(),rf_model()],use_probas = True,meta_classifier = lr,average_probas = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grid_search(mode):\r\n",
    "\tdef my_custom_loss_func(y_true, y_pred):\r\n",
    "\t\tdiff = np.mean(-y_true * np.log(y_pred + 1e-5))\r\n",
    "\t\treturn diff\r\n",
    "\tscore = make_scorer(my_custom_loss_func, greater_is_better=False)\r\n",
    "\t\r\n",
    "\t# grid search for lightgbm\r\n",
    "\tif mode=='lgb':\r\n",
    "\t\tparameters = {'max_depth': [5, 7, 9, 11], 'num_leaves': [16, 32, 64], 'reg_lambda': [7, 5,4, 3, 1, 0.1]}\r\n",
    "\t\tmodel = lightgbm_model()\r\n",
    "\t# grid search for catboost\r\n",
    "\tif mode=='cat':\r\n",
    "\t\tparameters = {'iterations': [3000, 4000, 5000],'max_depth': [ 6, 7, 8, 9],'learning_rate':[0.01, 0.008,0.005]}\r\n",
    "\t\tmodel = catboost_model()\r\n",
    "\t# grid search for xgboost\r\n",
    "\tif mode=='rf':\r\n",
    "\t\tparameters = {'n_estimators': [100, 500, 1000, 2000,3000],'max_depth': [5, 6, 7],'min_samples_leaf':[3,4,5,6],'min_samples_split':[3,4,5,6]}\r\n",
    "\t\tmodel = rf_model()\r\n",
    "\tif mode=='xgb':\r\n",
    "\t\tparameters = {'max_depth': [5, 7, 9, 11],'n_estimators':[1000, 2000, 3000], \r\n",
    "\t\t'min_child_weight' : [1,2,3,4],'colsample_bytree': [0.5,0.8]}\r\n",
    "\t\tmodel = xgboost_model()\r\n",
    "\tif mode=='sclf':\r\n",
    "\t    parameters = {\r\n",
    "\t       # 'lgbmclassifier__max_depth':[5,6, 7, 9],'lgbmclassifier__num_leaves':[16, 32], 'lgbmclassifier__reg_lambda':[6,5,4,3],\r\n",
    "\t       #这个网格搜索必须要用小写，但是还是报错了\r\n",
    "\t       # 'catboostclassifier__max_depth':[6, 7, 8, 9],'catboostclassifier__learning_rate':[0.01,0.008],\r\n",
    "\t       # 'xgbclassifier__max_depth':[5,6,7],'xgbclassifier__min_child_weight':[3,4],'xgbclassifier__n_estimators':[1000,2000]\r\n",
    "\t       # 'classifiers':[(catboost_model(),catboost_model()),(catboost_model(),lightgbm_model(), catboost_model()), (catboost_model(), xgboost_model(), catboost_model())],\r\n",
    "\t    }\r\n",
    "\t    model = sclf\r\n",
    "\t# search\r\n",
    "\tclf = GridSearchCV(model, parameters, cv=5, scoring=score, verbose=2)\r\n",
    "\tclf.fit(x_train, np.argmax(labels, 1))\r\n",
    "\tprint('best parameters:', clf.best_params_)\r\n",
    "\tprint('best score:', clf.best_score_)\r\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Feature Id', 'Importances'], dtype='object')\n",
      "Parameter10 : 24.267509971537823\n",
      "Parameter5 : 20.090112165080978\n",
      "7_10 : 12.460654797417952\n",
      "9_10 : 11.083609060881283\n",
      "7/8 : 6.12377978137922\n",
      "8/9 : 4.5603158575458185\n",
      "9%8 : 4.184016809120137\n",
      "7_9 : 3.9224417464041865\n",
      "7%8 : 2.9325470864020664\n",
      "8_9 : 2.876150105187855\n",
      "7_8 : 2.7068207490551535\n",
      "Parameter8 : 2.0746482020940413\n",
      "Parameter9 : 1.723738235353265\n",
      "Parameter7 : 0.9936554325402446\n"
     ]
    }
   ],
   "source": [
    "catboost_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# k-fold train\r\n",
    "def kfold_train(mode):\r\n",
    "\tacc_list, loss_list = [], []\r\n",
    "\tprediction = np.zeros((x_test.shape[0], 4))\r\n",
    "\tfor i in range(10):\r\n",
    "\t\tprint(str(i+1) + ' th kflod' + '*'*50)\r\n",
    "\t\tkf = KFold(n_splits=5, shuffle=True, random_state=i)\r\n",
    "\t\tkfold_list = []\r\n",
    "\t\tfor k, (train_index, test_index) in enumerate(kf.split(x_train)):\r\n",
    "\t\t\tprint(str(k+1) + 'fold--------------')\r\n",
    "\t\t\ttrain_x, train_y = x_train[train_index], labels[train_index]\r\n",
    "\t\t\ttest_x, test_y = x_train[test_index], labels[test_index]\r\n",
    "\t\t\t# train\r\n",
    "\t\t\tif mode == 'cat':\r\n",
    "\t\t\t\tmodel = catboost_model()\r\n",
    "\t\t\t\tmodel.fit(train_x, np.argmax(train_y, 1), eval_set=(test_x, np.argmax(test_y, 1)),\r\n",
    "\t\t\t\t\t  #early_stopping_rounds=1000, verbose=False\r\n",
    "\t\t\t\t\t\t)\r\n",
    "\t\t\t\t#print(pd.DataFrame({'column': features, 'importance': model.feature_importances_}).sort_values(by='importance'))\r\n",
    "\t\t\tif mode == 'lgb':\r\n",
    "\t\t\t\tmodel = lightgbm_model()\r\n",
    "\t\t\t\tmodel.fit(train_x, np.argmax(train_y, 1), eval_set=(test_x, np.argmax(test_y, 1)),\r\n",
    "\t\t\t\t\t  # early_stopping_rounds=50, verbose=True\r\n",
    "\t\t\t\t\t\t  verbose=False\r\n",
    "\t\t\t\t\t\t  )\r\n",
    "\t\t\tif mode == 'xgb':\r\n",
    "\t\t\t\tmodel = xgboost_model()\r\n",
    "\t\t\t\tmodel.fit(train_x, np.argmax(train_y, 1), verbose=True, eval_set=(test_x, np.argmax(test_y, 1)))\r\n",
    "\t\t\tif mode == 'sclf':\r\n",
    "\t\t\t\tmodel = sclf\r\n",
    "\t\t\t\tmodel.fit(train_x, np.argmax(train_y, 1))\r\n",
    "\t\t\tif mode == 'rf':\r\n",
    "\t\t\t\tmodel = rf_model()\r\n",
    "\t\t\t\tmodel.fit(train_x, np.argmax(train_y, 1))\r\n",
    "\t\t\tpred = model.predict_proba(test_x)\r\n",
    "\t\t\tacc = accuracy_score(np.argmax(test_y, 1), np.argmax(pred, 1))\r\n",
    "\t\t\tloss = log_loss(test_y, pred)\r\n",
    "\t\t\tacc_list.append(acc)\r\n",
    "\t\t\tloss_list.append(loss)\r\n",
    "\t\t\tkfold_list.append(loss)\r\n",
    "\t\t\tprint('test acc: %f, test loss: %f' % (acc, loss))\r\n",
    "\t\t\t# predict\r\n",
    "\t\t\tprediction += model.predict_proba(x_test)\r\n",
    "# \t\t\t返回的是概率\r\n",
    "\t\tprint('this fold mean loss:', np.mean(kfold_list))\r\n",
    "\tprint('*'*50)\r\n",
    "\tprint('mean acc: %f, mean loss: %f' % (np.mean(acc_list), np.mean(loss_list)))\r\n",
    "\tprediction = prediction / 50.\r\n",
    "\treturn prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 th kflod**************************************************\n",
      "1fold--------------\n"
     ]
    }
   ],
   "source": [
    "# from decimal import Decimal\r\n",
    "def submit_result(prediction):\r\n",
    "\tsub = test_data[['Group']]\r\n",
    "\tprob_cols = [i for i in submit.columns if i not in ['Group']]\r\n",
    "\tfor i, f in enumerate(prob_cols):\r\n",
    "\t\tsub[f] = prediction[:, i]\r\n",
    "\tfor i in prob_cols:\r\n",
    "\t\tsub[i] = sub.groupby('Group')[i].transform('mean')\r\n",
    "\tsub = sub.drop_duplicates()\r\n",
    "# \tfor i in prob_cols:\r\n",
    "\t   # sub[i] = sub[i].apply(lambda x:(Decimal(str(x))//Decimal('0.02')+Decimal('1'))*Decimal('0.02') if Decimal(str(x))%Decimal('0.02') > Decimal('0.01') else x)\r\n",
    "\t   # sub[i] = sub[i].apply(lambda x:(Decimal(str(x))//Decimal('0.02'))*Decimal('0.02') if Decimal(str(x))%Decimal('0.02') < Decimal('0.01') else x)\r\n",
    "\tsub.to_csv(\"/home/aistudio/work/result.csv\", index=False)\r\n",
    "\r\n",
    "time1 = time.clock()\r\n",
    "prediction = kfold_train('sclf')\r\n",
    "time2 = time.clock()\r\n",
    "print('running time: ', str((time2 - time1)/60))\r\n",
    "submit_result(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grid_search('rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.5.1 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
