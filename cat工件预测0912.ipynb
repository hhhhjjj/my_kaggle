{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_round_testin  first_round_traini\tsubmit_example.csv\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data/data12632/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result.csv\r\n"
     ]
    }
   ],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. All changes under this directory will be kept even after reset. Please clean unnecessary files in time to speed up environment loading.\n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\n",
      "Collecting catboost\n",
      "\u001b[?25l  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/7d/53/81cc0bfec6355978354f49e97391f8f6ece85f69f38429cbd3540f7dc3f8/catboost-0.17-cp35-none-manylinux1_x86_64.whl (62.1MB)\n",
      "\u001b[K    50% |████████████████▏               | 31.4MB 3.9MB/s eta 0:00:08"
     ]
    }
   ],
   "source": [
    "! pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ! pip install auto-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import catboost as cbt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "from xgboost import XGBClassifier\r\n",
    "import lightgbm as lgb\r\n",
    "from lightgbm import LGBMClassifier\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\r\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score,log_loss\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn.metrics import fbeta_score, make_scorer\r\n",
    "from tqdm import tqdm\r\n",
    "import matplotlib as mpl\r\n",
    "mpl.use('Agg')\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import time\r\n",
    "import copy\r\n",
    "import gc\r\n",
    "import os\r\n",
    "# import autosklearn.classification  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/home/aistudio/data/data12632/first_round_traini')\r\n",
    "test_data = pd.read_csv('/home/aistudio/data/data12632/first_round_testin', encoding='utf-8')\r\n",
    "dit = {'Excellent':0,'Good':1,'Pass':2,'Fail':3}\r\n",
    "train_data['Quality_label'] = train_data['Quality_label'].map(dit)\r\n",
    "labels = pd.get_dummies(train_data['Quality_label']).values\r\n",
    "submit = pd.read_csv('/home/aistudio/data/data12632/submit_example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 取parameter5-10，取log\r\n",
    "features = ['Parameter5', 'Parameter7', 'Parameter8', 'Parameter9', 'Parameter10']\r\n",
    "train_data[features] = np.log(train_data[features] + 1e-5)\r\n",
    "test_data[features] = np.log(test_data[features] + 1e-5)\r\n",
    "# 特征融合\r\n",
    "# train_data['5_6'] = train_data['Parameter5'] + train_data['Parameter6']\r\n",
    "# test_data['5_6'] = test_data['Parameter5'] + test_data['Parameter6']\r\n",
    "train_data['5_7'] = train_data['Parameter5'] + train_data['Parameter7']\r\n",
    "test_data['5_7'] = test_data['Parameter5'] + test_data['Parameter7']\r\n",
    "train_data['7_8'] = train_data['Parameter7'] + train_data['Parameter8']\r\n",
    "test_data['7_8'] = test_data['Parameter7'] + test_data['Parameter8']\r\n",
    "train_data['7_9'] = train_data['Parameter7'] + train_data['Parameter9']\r\n",
    "test_data['7_9'] = test_data['Parameter7'] + test_data['Parameter9']\r\n",
    "train_data['7_10'] = train_data['Parameter7'] + train_data['Parameter10']\r\n",
    "test_data['7_10'] = test_data['Parameter7'] + test_data['Parameter10']\r\n",
    "train_data['8_9'] = train_data['Parameter8'] + train_data['Parameter9']\r\n",
    "test_data['8_9'] = test_data['Parameter8'] + test_data['Parameter9']\r\n",
    "train_data['8_10'] = train_data['Parameter8'] + train_data['Parameter10']\r\n",
    "test_data['8_10'] = test_data['Parameter8'] + test_data['Parameter10']\r\n",
    "train_data['9_10'] = train_data['Parameter9'] + train_data['Parameter10']\r\n",
    "test_data['9_10'] = test_data['Parameter9'] + test_data['Parameter10']\r\n",
    "\r\n",
    "train_data['5_10'] = train_data['Parameter5'] + train_data['Parameter10']\r\n",
    "test_data['5_10'] = test_data['Parameter5'] + test_data['Parameter10']\r\n",
    "# train_data['6_10'] = train_data['Parameter6'] + train_data['Parameter10']\r\n",
    "# test_data['6_10'] = test_data['Parameter6'] + test_data['Parameter10']\r\n",
    "train_data['7_8_9'] = train_data['Parameter7'] + train_data['Parameter8'] + train_data['Parameter9']\r\n",
    "test_data['7_8_9'] = test_data['Parameter7'] + test_data['Parameter8'] + test_data['Parameter9']\r\n",
    "train_data['7_9_10'] = train_data['Parameter7'] + train_data['Parameter9'] + train_data['Parameter10']\r\n",
    "test_data['7_9_10'] = test_data['Parameter7'] + test_data['Parameter9'] + test_data['Parameter10']\r\n",
    "train_data['7_8_10'] = train_data['Parameter7'] + train_data['Parameter8'] + train_data['Parameter10']\r\n",
    "test_data['7_8_10'] = test_data['Parameter7'] + test_data['Parameter8'] + test_data['Parameter10']\r\n",
    "train_data['8_9_10'] = train_data['Parameter8'] + train_data['Parameter9'] + train_data['Parameter10']\r\n",
    "test_data['8_9_10'] = test_data['Parameter8'] + test_data['Parameter9'] + test_data['Parameter10']\r\n",
    "train_data['7_8_9_10'] = train_data['Parameter7'] + train_data['Parameter8'] + train_data['Parameter9'] + train_data['Parameter10']\r\n",
    "test_data['7_8_9_10'] = test_data['Parameter7'] + test_data['Parameter8'] + test_data['Parameter9'] + test_data['Parameter10']\r\n",
    "\r\n",
    "# train_data['5-6'] = (train_data['Parameter5'] - train_data['Parameter6'])\r\n",
    "# test_data['5-6'] = (test_data['Parameter5'] - test_data['Parameter6'])\r\n",
    "train_data['7-8'] = (train_data['Parameter7'] - train_data['Parameter8'])\r\n",
    "test_data['7-8'] = (test_data['Parameter7'] - test_data['Parameter8'])\r\n",
    "train_data['7-9'] = (train_data['Parameter7'] - train_data['Parameter9'])\r\n",
    "test_data['7-9'] = (test_data['Parameter7'] - test_data['Parameter9'])\r\n",
    "train_data['7-10'] = (train_data['Parameter7'] - train_data['Parameter10'])\r\n",
    "test_data['7-10'] = (test_data['Parameter7'] - test_data['Parameter10'])\r\n",
    "train_data['8-9'] = (train_data['Parameter8'] - train_data['Parameter9'])\r\n",
    "test_data['8-9'] = (test_data['Parameter8'] - test_data['Parameter9'])\r\n",
    "train_data['8-10'] = (train_data['Parameter8'] - train_data['Parameter10'])\r\n",
    "test_data['8-10'] = (test_data['Parameter8'] - test_data['Parameter10'])\r\n",
    "train_data['9-10'] = (train_data['Parameter9'] - train_data['Parameter10'])\r\n",
    "test_data['9-10'] = (test_data['Parameter9'] - test_data['Parameter10'])\r\n",
    "\r\n",
    "# train_data['5_6_mul'] = train_data['Parameter5'].mul(train_data['Parameter6'])\r\n",
    "# test_data['5_6_mul'] = test_data['Parameter5'].mul(test_data['Parameter6'])\r\n",
    "train_data['7_8_mul'] = train_data['Parameter7'].mul(train_data['Parameter8'])\r\n",
    "test_data['7_8_mul'] = test_data['Parameter7'].mul(test_data['Parameter8'])\r\n",
    "train_data['7_9_mul'] = train_data['Parameter7'].mul(train_data['Parameter9'])\r\n",
    "test_data['7_9_mul'] = test_data['Parameter7'].mul(test_data['Parameter9'])\r\n",
    "train_data['7_10_mul'] = train_data['Parameter7'].mul(train_data['Parameter10'])\r\n",
    "test_data['7_10_mul'] = test_data['Parameter7'].mul(test_data['Parameter10'])\r\n",
    "train_data['8_9_mul'] = train_data['Parameter8'].mul(train_data['Parameter9'])\r\n",
    "test_data['8_9_mul'] = test_data['Parameter8'].mul(test_data['Parameter9'])\r\n",
    "train_data['8_10_mul'] = train_data['Parameter8'].mul(train_data['Parameter10'])\r\n",
    "test_data['8_10_mul'] = test_data['Parameter8'].mul(test_data['Parameter10'])\r\n",
    "train_data['9_10_mul'] = train_data['Parameter9'].mul(train_data['Parameter10'])\r\n",
    "test_data['9_10_mul'] = test_data['Parameter9'].mul(test_data['Parameter10'])\r\n",
    "\r\n",
    "train_data['78_mul_79'] = (train_data['7_8'].mul(train_data['7_9']))\r\n",
    "test_data['78_mul_79'] = (test_data['7_8'].mul(test_data['7_9']))\r\n",
    "train_data['78_mul_710'] = (train_data['7_8'].mul(train_data['7_10']))\r\n",
    "test_data['78_mul_710'] = (test_data['7_8'].mul(test_data['7_10']))\r\n",
    "train_data['78_mul_89'] = (train_data['7_8'].mul(train_data['8_9']))\r\n",
    "test_data['78_mul_89'] = (test_data['7_8'].mul(test_data['8_9']))\r\n",
    "train_data['78_mul_810'] = (train_data['7_8'].mul(train_data['8_10']))\r\n",
    "test_data['78_mul_810'] = (test_data['7_8'].mul(test_data['8_10']))\r\n",
    "train_data['78_mul_910'] = (train_data['7_8'].mul(train_data['9_10']))\r\n",
    "test_data['78_mul_910'] = (test_data['7_8'].mul(test_data['9_10']))\r\n",
    "train_data['79_mul_710'] = (train_data['7_9'].mul(train_data['7_10']))\r\n",
    "test_data['79_mul_710'] = (test_data['7_9'].mul(test_data['7_10']))\r\n",
    "train_data['79_mul_89'] = (train_data['7_9'].mul(train_data['8_9']))\r\n",
    "test_data['79_mul_89'] = (test_data['7_9'].mul(test_data['8_9']))\r\n",
    "train_data['79_mul_810'] = (train_data['7_9'].mul(train_data['8_10']))\r\n",
    "test_data['79_mul_810'] = (test_data['7_9'].mul(test_data['8_10']))\r\n",
    "train_data['79_mul_910'] = (train_data['7_9'].mul(train_data['9_10']))\r\n",
    "test_data['79_mul_910'] = (test_data['7_9'].mul(test_data['9_10']))\r\n",
    "train_data['710_mul_89'] = (train_data['7_10'].mul(train_data['8_9']))\r\n",
    "test_data['710_mul_89'] = (test_data['7_10'].mul(test_data['8_9']))\r\n",
    "train_data['710_mul_810'] = (train_data['7_10'].mul(train_data['8_10']))\r\n",
    "test_data['710_mul_810'] = (test_data['7_10'].mul(test_data['8_10']))\r\n",
    "train_data['710_mul_910'] = (train_data['7_10'].mul(train_data['9_10']))\r\n",
    "test_data['710_mul_910'] = (test_data['7_10'].mul(test_data['9_10']))\r\n",
    "train_data['89_mul_810'] = (train_data['8_9'].mul(train_data['8_10']))\r\n",
    "test_data['89_mul_810'] = (test_data['8_9'].mul(test_data['8_10']))\r\n",
    "train_data['89_mul_910'] = (train_data['8_9'].mul(train_data['9_10']))\r\n",
    "test_data['89_mul_910'] = (test_data['8_9'].mul(test_data['9_10']))\r\n",
    "train_data['810_mul_910'] = (train_data['8_10'].mul(train_data['9_10']))\r\n",
    "test_data['810_mul_910'] = (test_data['8_10'].mul(test_data['9_10']))\r\n",
    "\r\n",
    "train_data['5_8'] = train_data['Parameter5'] + train_data['Parameter8']\r\n",
    "test_data['5_8'] = test_data['Parameter5'] + test_data['Parameter8']\r\n",
    "train_data['7+8*8'] = train_data['Parameter7'] + train_data['Parameter8'] * train_data['Parameter8']\r\n",
    "test_data['7+8*8'] = test_data['Parameter7'] + test_data['Parameter8'] * test_data['Parameter8']\r\n",
    "train_data['7*7+8'] = train_data['Parameter7'] * train_data['Parameter7'] + train_data['Parameter8']\r\n",
    "test_data['7*7+8'] = test_data['Parameter7'] * test_data['Parameter7'] + test_data['Parameter8']\r\n",
    "\r\n",
    "train_data['9/7'] = train_data['Parameter9'] / train_data['Parameter7']\r\n",
    "test_data['9/7'] = test_data['Parameter9'] / test_data['Parameter7']\r\n",
    "train_data['9/8'] = train_data['Parameter9'] / train_data['Parameter8']\r\n",
    "test_data['9/8'] = test_data['Parameter9'] / test_data['Parameter8']\r\n",
    "train_data['1/7'] = 1. / train_data['Parameter7']\r\n",
    "test_data['1/7'] = 1. / test_data['Parameter7']\r\n",
    "train_data['9%8'] = train_data['Parameter9'] % train_data['Parameter8']\r\n",
    "test_data['9%8'] = test_data['Parameter9'] % test_data['Parameter8']\r\n",
    "train_data['7%9'] = train_data['Parameter7'] % train_data['Parameter9']\r\n",
    "test_data['7%9'] = test_data['Parameter7'] % test_data['Parameter9']\r\n",
    "train_data['1/9'] = 1. / train_data['Parameter9']\r\n",
    "test_data['1/9'] = 1. / test_data['Parameter9']\r\n",
    "train_data['7/8'] = train_data['Parameter7'] / train_data['Parameter8']\r\n",
    "test_data['7/8'] = test_data['Parameter7'] / test_data['Parameter8']\r\n",
    "train_data['8%9'] = train_data['Parameter8'] % train_data['Parameter9']\r\n",
    "test_data['8%9'] = test_data['Parameter8'] % test_data['Parameter9']\r\n",
    "train_data['7/9'] = train_data['Parameter7'] / train_data['Parameter9']\r\n",
    "test_data['7/9'] = test_data['Parameter7'] / test_data['Parameter9']\r\n",
    "train_data['8/7'] = train_data['Parameter8'] / train_data['Parameter7']\r\n",
    "test_data['8/7'] = test_data['Parameter8'] / test_data['Parameter7']\r\n",
    "train_data['1/8'] = 1. / train_data['Parameter8']\r\n",
    "test_data['1/8'] = 1. / test_data['Parameter8']\r\n",
    "train_data['8%7'] = train_data['Parameter8'] % train_data['Parameter7']\r\n",
    "test_data['8%7'] = test_data['Parameter8'] % test_data['Parameter7']\r\n",
    "train_data['8+9/8%9'] = (train_data['Parameter8'] + train_data['Parameter9']) / train_data['Parameter8'] % train_data['Parameter9']\r\n",
    "test_data['8+9/8%9'] = (test_data['Parameter8'] + test_data['Parameter9']) / test_data['Parameter8'] % test_data['Parameter9']\r\n",
    "train_data['7%8'] = train_data['Parameter7'] % train_data['Parameter8']\r\n",
    "test_data['7%8'] = test_data['Parameter7'] % test_data['Parameter8']\r\n",
    "train_data['8/9'] = train_data['Parameter8'] / train_data['Parameter9']\r\n",
    "test_data['8/9'] = test_data['Parameter8'] / test_data['Parameter9']\r\n",
    "\r\n",
    "train_data['7+8%7+9'] = train_data['Parameter7'] + train_data['Parameter8'] % train_data['Parameter7'] + train_data['Parameter9']\r\n",
    "test_data['7+8%7+9'] = test_data['Parameter7'] + test_data['Parameter8'] % test_data['Parameter7'] + test_data['Parameter9']\r\n",
    "train_data['1/8/9'] = 1./train_data['Parameter8']/train_data['Parameter9']\r\n",
    "test_data['1/8/9'] = 1./test_data['Parameter8']/test_data['Parameter9']\r\n",
    "train_data['9%7/9'] = train_data['Parameter9']%train_data['Parameter7']/train_data['Parameter9']\r\n",
    "test_data['9%7/9'] = test_data['Parameter9']%test_data['Parameter7']/test_data['Parameter9']\r\n",
    "train_data['8+9/8*9'] = train_data['Parameter8']+train_data['Parameter9']/train_data['Parameter8']*train_data['Parameter9']\r\n",
    "test_data['8+9/8*9'] = test_data['Parameter8']+test_data['Parameter9']/test_data['Parameter8']*test_data['Parameter9']\r\n",
    "train_data['9%7/7*8'] = train_data['Parameter9']%train_data['Parameter7']/train_data['Parameter7']*train_data['Parameter8']\r\n",
    "test_data['9%7/7*8'] = test_data['Parameter9']%test_data['Parameter7']/test_data['Parameter7']*test_data['Parameter8']\r\n",
    "train_data['7%8/7'] = train_data['Parameter7']%train_data['Parameter8']/train_data['Parameter7']\r\n",
    "test_data['7%8/7'] = test_data['Parameter7']%test_data['Parameter8']/test_data['Parameter7']\r\n",
    "train_data['9%8*9'] = train_data['Parameter9']%train_data['Parameter8']*train_data['Parameter9']\r\n",
    "test_data['9%8*9'] = test_data['Parameter9']%test_data['Parameter8']*test_data['Parameter9']\r\n",
    "train_data['8*9%7'] = train_data['Parameter8']*train_data['Parameter9']%train_data['Parameter7']\r\n",
    "test_data['8*9%7'] = test_data['Parameter8']*test_data['Parameter9']%test_data['Parameter7']\r\n",
    "\r\n",
    "train_data['8%9*8'] = train_data['Parameter8']%train_data['Parameter9']*train_data['Parameter8']\r\n",
    "test_data['8%9*8'] = test_data['Parameter8']%test_data['Parameter9']*test_data['Parameter8']\r\n",
    "train_data['7*8*9'] = train_data['Parameter8']*train_data['Parameter7']*train_data['Parameter9']\r\n",
    "test_data['7*8*9'] = test_data['Parameter8']*test_data['Parameter7']*test_data['Parameter9']\r\n",
    "train_data['8+9/7*8']=train_data['Parameter8']+train_data['Parameter9']/train_data['Parameter7']*train_data['Parameter9']\r\n",
    "test_data['8+9/7*8']=test_data['Parameter8']+test_data['Parameter9']/test_data['Parameter7']*test_data['Parameter9']\r\n",
    "train_data['8%7/(9%8)'] = train_data['Parameter8']%train_data['Parameter7']/(train_data['Parameter9']%train_data['Parameter8'])\r\n",
    "test_data['8%7/(9%8)'] = test_data['Parameter8']%test_data['Parameter7']/(test_data['Parameter9']%test_data['Parameter8'])\r\n",
    "train_data['7%8/(8%9)'] = train_data['Parameter7']%train_data['Parameter8']/(train_data['Parameter8']%train_data['Parameter9'])\r\n",
    "test_data['7%8/(8%9)'] = test_data['Parameter7']%test_data['Parameter8']/(test_data['Parameter8']%test_data['Parameter9'])\r\n",
    "train_data['8+9/(9%8)']=train_data['Parameter8']+train_data['Parameter9']/(train_data['Parameter9']%train_data['Parameter8'])\r\n",
    "test_data['8+9/(9%8)']=test_data['Parameter8']+test_data['Parameter9']/(test_data['Parameter9']%test_data['Parameter8'])\r\n",
    "train_data['8*(9%7)+8'] = train_data['Parameter8']*(train_data['Parameter9']%train_data['Parameter7']+train_data['Parameter8'])\r\n",
    "test_data['8*(9%7)+8'] = test_data['Parameter8']*(test_data['Parameter9']%test_data['Parameter7']+test_data['Parameter8'])\r\n",
    "train_data['7+8*9'] = train_data['Parameter7']+train_data['Parameter8']*train_data['Parameter9']\r\n",
    "test_data['7+8*9'] = test_data['Parameter7']+test_data['Parameter8']*test_data['Parameter9']\r\n",
    "train_data['7%8/(9%8)'] = train_data['Parameter7']%train_data['Parameter8']/(train_data['Parameter9']%train_data['Parameter8'])\r\n",
    "test_data['7%8/(9%8)'] = test_data['Parameter7']%test_data['Parameter8']/(test_data['Parameter9']%test_data['Parameter8'])\r\n",
    "train_data['9%8/(7%8)'] = train_data['Parameter9']%train_data['Parameter8']/(train_data['Parameter7']%train_data['Parameter8'])\r\n",
    "test_data['9%8/(7%8)'] = test_data['Parameter9']%test_data['Parameter8']/(test_data['Parameter7']%test_data['Parameter8'])\r\n",
    "train_data['5%8'] = train_data['Parameter5']%train_data['Parameter8']\r\n",
    "test_data['5%8'] = test_data['Parameter5']%test_data['Parameter8']\r\n",
    "# train_data['6%8'] = train_data['Parameter6']%train_data['Parameter8']\r\n",
    "# test_data['6%8'] = test_data['Parameter6']%test_data['Parameter8']\r\n",
    "train_data['10%8'] = train_data['Parameter10']%train_data['Parameter8']\r\n",
    "test_data['10%8'] = test_data['Parameter10']%test_data['Parameter8']\r\n",
    "\r\n",
    "train_data['7*8'] = train_data['Parameter7'] * train_data['Parameter8']\r\n",
    "test_data['7*8'] = test_data['Parameter7'] * test_data['Parameter8']\r\n",
    "train_data['5*5'] = train_data['Parameter5'] * train_data['Parameter5']\r\n",
    "test_data['5*5'] = test_data['Parameter5'] * test_data['Parameter5']\r\n",
    "# train_data['6*6'] = train_data['Parameter6'] * train_data['Parameter6']\r\n",
    "# test_data['6*6'] = test_data['Parameter6'] * test_data['Parameter6']\r\n",
    "train_data['7*7'] = train_data['Parameter7'] * train_data['Parameter7']\r\n",
    "test_data['7*7'] = test_data['Parameter7'] * test_data['Parameter7']\r\n",
    "train_data['8*8'] = train_data['Parameter8'] * train_data['Parameter8']\r\n",
    "test_data['8*8'] = test_data['Parameter8'] * test_data['Parameter8']\r\n",
    "train_data['9*9'] = train_data['Parameter9'] * train_data['Parameter9']\r\n",
    "test_data['9*9'] = test_data['Parameter9'] * test_data['Parameter9']\r\n",
    "train_data['10*10'] = train_data['Parameter10'] * train_data['Parameter10']\r\n",
    "test_data['10*10'] = test_data['Parameter10'] * test_data['Parameter10']\r\n",
    "\r\n",
    "scale_features = [\r\n",
    "    # '5_6',\r\n",
    "    '7_9', '8_9', '7_8', '8_10', '9_10', '7_10', '9%8', '7/8', '7%8', '8/9',\r\n",
    "\t\t\t\t  ]\r\n",
    "\r\n",
    "\r\n",
    "# 组合所有特征\r\n",
    "features = features + scale_features\r\n",
    "\r\n",
    "print('all train features:', features)\r\n",
    "\r\n",
    "for fc in features:\r\n",
    "\tn = train_data['{}'.format(fc)].nunique()\r\n",
    "# \t这个的左右就是显示特征中的唯一值\r\n",
    "\tprint(fc + ':', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_data.sort_values('Parameter2', ascending=False)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\r\n",
    "# train\r\n",
    "# --------------------------------------------------------\r\n",
    "x_train = train_data[features].values\r\n",
    "x_test = test_data[features].values\r\n",
    "\r\n",
    "def lightgbm_model():\r\n",
    "\tmodel = LGBMClassifier(max_depth=7, learning_rate=0.01, n_estimators=1000, num_leaves=16,\r\n",
    "\t\t\t\t\t\t   objective='multiclass', silent=True,\r\n",
    "\t\t\t\t\t\t   reg_lambda=4., #reg_alpha=1.,\r\n",
    "\t\t\t\t\t\t   #bagging_fraction=0.9, feature_fraction=0.9,\r\n",
    "\t\t\t\t\t\t   )\r\n",
    "\treturn model\r\n",
    "\r\n",
    "def xgboost_model():\r\n",
    "\tmodel = XGBClassifier(max_depth=5, n_estimators=1000, learning_rate=0.01, silent=True,\r\n",
    "\t\t\t\t\t\t  #objective='multi:softmax',\r\n",
    "\t\t\t\t\t\t  )\r\n",
    "\treturn model\r\n",
    "\r\n",
    "def catboost_model():\r\n",
    "\tcbt_model = cbt.CatBoostClassifier(#iterations=100000, learning_rate=0.01, verbose=0,\r\n",
    "\t\titerations=3000, learning_rate=0.01, verbose=0,\r\n",
    "\t\tmax_depth=7, #reg_lambda=5.,\r\n",
    "\t\ttask_type='CPU',   # cat_features=cat_list,\r\n",
    "\t\tloss_function='MultiClass',\r\n",
    "# \t\tl2_leaf_reg = 7\r\n",
    "\t\t)\r\n",
    "\treturn cbt_model\r\n",
    "\r\n",
    "def catboost_importance():\r\n",
    "\tmodel = catboost_model()\r\n",
    "\tmodel.fit(x_train, np.argmax(labels, 1))\r\n",
    "\timportance = model.get_feature_importance(prettified=True)\r\n",
    "# \t这个其实就是类似PCA一样，找到特征的贡献\r\n",
    "\tprint(importance.columns)\r\n",
    "\tfor i in range(len(features)):\r\n",
    "\t\tprint(features[int(importance['Feature Id'][i])] + ' :', importance['Importances'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grid_search(mode):\r\n",
    "\tdef my_custom_loss_func(y_true, y_pred):\r\n",
    "\t\tdiff = np.mean(-y_true * np.log(y_pred + 1e-5))\r\n",
    "\t\treturn diff\r\n",
    "\tscore = make_scorer(my_custom_loss_func, greater_is_better=False)\r\n",
    "\t\r\n",
    "\t# grid search for lightgbm\r\n",
    "\tif mode=='lgb':\r\n",
    "\t\tparameters = {'max_depth': [5, 7, 9, 11], 'num_leaves ': [16, 32, 64], 'reg_lambda': [10, 5, 3, 1, 0.1]}\r\n",
    "\t\tmodel = lightgbm_model()\r\n",
    "\t# grid search for catboost\r\n",
    "\tif mode=='cat':\r\n",
    "\t\tparameters = {'l2_leaf_reg': [2, 3, 4, 5, 6, 7, 8],'max_depth': [ 6, 7, 8, 9]}\r\n",
    "\t\tmodel = catboost_model()\r\n",
    "\t# grid search for xgboost\r\n",
    "\tif mode=='xgb':\r\n",
    "\t\tparameters = {'max_depth': [5, 7, 9, 11]}\r\n",
    "\t\tmodel = catboost_model()\r\n",
    "\t# search\r\n",
    "\tclf = GridSearchCV(model, parameters, cv=5, scoring=score, verbose=2)\r\n",
    "\tclf.fit(x_train, np.argmax(labels, 1))\r\n",
    "\tprint('best parameters:', clf.best_params_)\r\n",
    "\tprint('best score:', clf.best_score_)\r\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catboost_importance()\r\n",
    "# k-fold train\r\n",
    "def kfold_train(mode):\r\n",
    "\tacc_list, loss_list = [], []\r\n",
    "\tprediction = np.zeros((x_test.shape[0], 4))\r\n",
    "\tfor i in range(10):\r\n",
    "\t\tprint(str(i+1) + ' th kflod' + '*'*50)\r\n",
    "\t\tkf = KFold(n_splits=5, shuffle=True, random_state=i)\r\n",
    "\t\tkfold_list = []\r\n",
    "\t\tfor k, (train_index, test_index) in enumerate(kf.split(x_train)):\r\n",
    "\t\t\tprint(str(k+1) + 'fold--------------')\r\n",
    "\t\t\ttrain_x, train_y = x_train[train_index], labels[train_index]\r\n",
    "\t\t\ttest_x, test_y = x_train[test_index], labels[test_index]\r\n",
    "\t\t\t# train\r\n",
    "\t\t\tif mode == 'cat':\r\n",
    "\t\t\t\tmodel = catboost_model()\r\n",
    "\t\t\t\tmodel.fit(train_x, np.argmax(train_y, 1), eval_set=(test_x, np.argmax(test_y, 1)),\r\n",
    "\t\t\t\t\t  #early_stopping_rounds=1000, verbose=False\r\n",
    "\t\t\t\t\t\t)\r\n",
    "\t\t\t\t#print(pd.DataFrame({'column': features, 'importance': model.feature_importances_}).sort_values(by='importance'))\r\n",
    "\t\t\tif mode == 'lgb':\r\n",
    "\t\t\t\tmodel = lightgbm_model()\r\n",
    "\t\t\t\tmodel.fit(train_x, np.argmax(train_y, 1), eval_set=(test_x, np.argmax(test_y, 1)),\r\n",
    "\t\t\t\t\t  # early_stopping_rounds=50, verbose=True\r\n",
    "\t\t\t\t\t\t  verbose=False\r\n",
    "\t\t\t\t\t\t  )\r\n",
    "\t\t\tif mode == 'xgb':\r\n",
    "\t\t\t\tmodel = xgboost_model()\r\n",
    "\t\t\t\tmodel.fit(train_x, np.argmax(train_y, 1), verbose=True)\r\n",
    "# \t\t\tif mode == 'automl':\r\n",
    "# \t\t\t    automl = autosklearn.classification.AutoSklearnClassifier() \r\n",
    "\t\t\t #   automl.fit(train_x, np.argmax(train_y, 1)) \r\n",
    "\t\t\t# test\r\n",
    "\t\t\tpred = model.predict_proba(test_x)\r\n",
    "\t\t\tacc = accuracy_score(np.argmax(test_y, 1), np.argmax(pred, 1))\r\n",
    "\t\t\tloss = log_loss(test_y, pred)\r\n",
    "\t\t\tacc_list.append(acc)\r\n",
    "\t\t\tloss_list.append(loss)\r\n",
    "\t\t\tkfold_list.append(loss)\r\n",
    "\t\t\tprint('test acc: %f, test loss: %f' % (acc, loss))\r\n",
    "\t\t\t# predict\r\n",
    "\t\t\tprediction += model.predict_proba(x_test)\r\n",
    "# \t\t\t返回的是概率\r\n",
    "\t\tprint('this fold mean loss:', np.mean(kfold_list))\r\n",
    "\tprint('*'*50)\r\n",
    "\tprint('mean acc: %f, mean loss: %f' % (np.mean(acc_list), np.mean(loss_list)))\r\n",
    "\tprediction = prediction / 50.\r\n",
    "\treturn prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def submit_result(prediction):\r\n",
    "\tsub = test_data[['Group']]\r\n",
    "\tprob_cols = [i for i in submit.columns if i not in ['Group']]\r\n",
    "\tfor i, f in enumerate(prob_cols):\r\n",
    "\t\tsub[f] = prediction[:, i]\r\n",
    "\tfor i in prob_cols:\r\n",
    "\t\tsub[i] = sub.groupby('Group')[i].transform('mean')\r\n",
    "\tsub = sub.drop_duplicates()\r\n",
    "\tsub.to_csv(\"/home/aistudio/work/result.csv\", index=False)\r\n",
    "\r\n",
    "time1 = time.clock()\r\n",
    "prediction = kfold_train('cat')\r\n",
    "time2 = time.clock()\r\n",
    "print('running time: ', str((time2 - time1)/60))\r\n",
    "submit_result(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grid_search('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.5.1 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
